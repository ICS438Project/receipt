{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a6085c",
   "metadata": {},
   "source": [
    "# 0) Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f37afca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install langchain OpenAI torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4959b784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from jsonschema import validate\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de17159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATERECEIPTS = False\n",
    "UPDATEVENDOREMBEDDATABASE = False\n",
    "UPDATEPRODUCTEMBEDDATABASE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99e27e",
   "metadata": {},
   "source": [
    "# 1) Use ChatGPT to convert receipt text into structured JSON\n",
    "\n",
    "* Make sure it generates correct data (use asserts to test all of this)\n",
    "* Make sure edge cases are handled (ex: blank fields, fields not in correct datatype, dollar sign in total, phone number larger than 10 digits)\n",
    "* Prevent language model from returning invalid json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bec517",
   "metadata": {},
   "source": [
    "## OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "11da93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38501d6c",
   "metadata": {},
   "source": [
    "## ChatGPT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81ee6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Please analyze the provided receipt and extract relevant information to fill in the following structured format:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"(string value)\",\n",
    "    \"address\": \"(string value)\", (split into street address, city, and state)\n",
    "    \"city\": \"(string value)\",\n",
    "    \"state\": \"(string value)\",\n",
    "    \"phoneNumber\": \"(string value)\",\n",
    "    \"tax\": \"(float value)\", (in dollars)\n",
    "    \"total\": \"(float value)\", (in dollars)\n",
    "    \"receiptDate\": \"(string value)\",\n",
    "    \"receiptTime\": \"(string value)\", (if available)\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"(string value)\",\n",
    "        \"quantity\": \"(integer value)\",\n",
    "        \"unitPrice\": \"(float value)\",\n",
    "        \"totalPrice\": \"(float value)\",\n",
    "        \"discountAmount\": \"(float value)\" if any\n",
    "      }, ...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "Remember to check for any discounts or special offers applied to the items and reflect these in the item details. Make sure to end the json object and make sure it's in json format.\n",
    "1. tax, total, unitPrice, totalPrice, discountAmount in float value, and quantity in integer value\n",
    "2. ignore all <UNKNOWN> in the text\n",
    "3. Your response should start with { and end with },\n",
    "4. make sure close all ReceiptInfo and use , to separate different ReceiptInfo\n",
    "\n",
    "example: \"\"\"Marley's Shop\n",
    "123 Long Rd\n",
    "Kailua, HI 67530\n",
    "(808) 555-1234\n",
    "CASHIER: JOHN\n",
    "REGISTER #: 6\n",
    "04/12/2023\n",
    "Transaction ID: 5769009\n",
    "PRICE   QTY  TOTAL\n",
    "APPLES (1 lb)\n",
    "2.99 2 5.98  1001\n",
    "-1.00  999\n",
    "Choco Dream Cookies\n",
    "7.59 1 7.59   1001\n",
    "SUBTOTAL\n",
    "13.57\n",
    "SALES TAX 8.5%\n",
    "1.15\n",
    "TOTAL\n",
    "-14.72\n",
    "VISA CARD            14.72\n",
    "CARD#: **1234\n",
    "REFERENCE#: 6789\n",
    "THANK YOU FOR SHOPPING WITH US!\n",
    "\"\"\"\n",
    "\n",
    "from example should get:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"Marley's Shop\",\n",
    "    \"address\": \"123 Long Rd\",\n",
    "    \"city\": \"Kailua\",\n",
    "    \"state\": \"HI\",\n",
    "    \"phoneNumber\": \"(xxx) xxx-xxxx\",\n",
    "    \"tax\": 1.15,\n",
    "    \"total\": 14.72,\n",
    "    \"receiptDate\": \"04/12/2023\",\n",
    "    \"receiptTime\": \"Transaction ID: 5769009\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"APPLES (1 lb)\",\n",
    "        \"quantity\": 2,\n",
    "        \"unitPrice\": 2.99,\n",
    "        \"totalPrice\": 5.98,\n",
    "        \"discountAmount\": 1.00\n",
    "      },\n",
    "      {\n",
    "        \"description\": \"Choco Dream Cookies\",\n",
    "        \"quantity\": 1,\n",
    "        \"unitPrice\": 7.59,\n",
    "        \"totalPrice\": 7.59,\n",
    "        \"discountAmount\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025a1cd",
   "metadata": {},
   "source": [
    "## Read in all receipt texts, convert to list of JSON, and output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6af1c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder_path):\n",
    "    text_list = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path.\")\n",
    "        return None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "                text_list.append(file_content)  # Append file content as a string to the list\n",
    "                \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a958fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ReceiptInfo\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"merchant\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"state\": {\"type\": \"string\"},\n",
    "                    \"phoneNumber\": {\"type\": \"string\"},\n",
    "                    \"tax\": {\"type\": \"number\"},\n",
    "                    \"total\": {\"type\": \"number\"},\n",
    "                    \"receiptDate\": {\"type\": \"string\"},\n",
    "                    \"ITEMS\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"description\": {\"type\": \"string\"},\n",
    "                                \"quantity\": {\"type\": \"number\"},\n",
    "                                \"unitPrice\": {\"type\": \"number\"},\n",
    "                                \"totalPrice\": {\"type\": \"number\"},\n",
    "                                \"discountAmount\": {\"type\": \"number\"}\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "def process_and_validate_json(response, schema):\n",
    "    # Find the index of the first '{'\n",
    "    brace_index = response.find('{')\n",
    "    \n",
    "    # If '{' is found and it's not the first character\n",
    "    if brace_index != -1:\n",
    "        # Extract JSON from the substring starting from the first '{'\n",
    "        extracted_json = response[brace_index:]\n",
    "        \n",
    "        # Validate the extracted JSON against the provided schema\n",
    "        try:\n",
    "            validate(instance=json.loads(extracted_json), schema=schema)\n",
    "            return extracted_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "        except ValidationError as e:\n",
    "            print(f\"JSON validation error: {e}\")\n",
    "    \n",
    "    # Return None if '{' is not found or it's the first character\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0cf370ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text):\n",
    "    llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=openai_api_key, max_tokens=1056)\n",
    "    response = llm(input_text)\n",
    "    return process_and_validate_json(response, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cf8a4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "if UPDATERECEIPTS:\n",
    "    folder_path = './receipts/text'\n",
    "    file_path = f'./entities.json'\n",
    "\n",
    "    receipts = read_text_files(folder_path)\n",
    "\n",
    "    receipts_json = []\n",
    "    errorReceipts = []\n",
    "    files_processed = 0\n",
    "    for receipt in receipts:\n",
    "        receipt_json = json.loads(generate_response(prompt + receipt))\n",
    "        receipts_json.append(receipt_json)\n",
    "        files_processed += 1\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(receipts_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e926b32",
   "metadata": {},
   "source": [
    "# 2) Create vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc5ed1",
   "metadata": {},
   "source": [
    "## Load BertTokenizer and BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9bf8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2a3ab",
   "metadata": {},
   "source": [
    "## Convert word to embeddings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e898b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(word):\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling of token embeddings\n",
    "    return embeddings\n",
    "    \n",
    "# Function to convert words in a DataFrame column to embeddings\n",
    "def convert_to_embeddings_df(df):\n",
    "    embeddings = [generate_embeddings(x) for x in df.iloc[:, 0]] \n",
    "    dfs = []\n",
    "    for embedding in embeddings:\n",
    "        dfs.append(pd.DataFrame(embedding))\n",
    "    return pd.concat(dfs)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551cbd1",
   "metadata": {},
   "source": [
    "## Create vector database for vendors and output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e36e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVendorEmbeddedDatabase():    \n",
    "    folder_path = './vendor database/' \n",
    "    vendorDatabase = pd.DataFrame()\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        category = file.split('/')[-1]\n",
    "        category_name = category.split('_')[0]\n",
    "        newCategory = pd.read_csv(file, encoding='latin-1')\n",
    "        newColumn = convert_to_embeddings_df(newCategory)\n",
    "        newColumn['Category'] = category_name\n",
    "        vendorDatabase = pd.concat([vendorDatabase, newColumn], ignore_index=True, axis=0)\n",
    "    vendorDatabase.to_csv(\"./embeddedVendorDatabase.csv\")\n",
    "\n",
    "        \n",
    "    return vendorDatabase\n",
    "\n",
    "if UPDATEVENDOREMBEDDATABASE:\n",
    "    getVendorEmbeddedDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d761f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductEmbeddedDatabase():\n",
    "\n",
    "    # Directory path containing subfolders with product CSV files\n",
    "    root_folder = './product database/'\n",
    "    productDatabase = pd.DataFrame()\n",
    "\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Get the absolute path of the CSV file\n",
    "                csv_file_path = os.path.join(root, file)\n",
    "                category = csv_file_path.split('/')[-2]\n",
    "                category_name = category.split('_')[0]\n",
    "                #print(csv_file_path)\n",
    "                newCategory = pd.read_csv(csv_file_path, encoding='latin-1')\n",
    "                newColumn = convert_to_embeddings_df(newCategory)\n",
    "                newColumn['Category'] = category_name\n",
    "                productDatabase = pd.concat([productDatabase, newColumn], ignore_index=True, axis=0)\n",
    "    productDatabase.to_csv(\"./embeddedProductDatabase.csv\")\n",
    "\n",
    "        \n",
    "    return productDatabase\n",
    "\n",
    "if UPDATEPRODUCTEMBEDDATABASE:\n",
    "    getProductEmbeddedDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90e4f4",
   "metadata": {},
   "source": [
    "## Split vector database into X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bdcc3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddedDatabase(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    # Creating variables from database values\n",
    "    X = df.drop('Category', axis=1)\n",
    "    y = df['Category']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "32a7c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReceiptTestData():\n",
    "    # Read and parse the JSON file\n",
    "    with open('./entities.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    entry_number = 0\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    merchants = []\n",
    "    descriptions = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for entry in data:\n",
    "        entry_number += 1 \n",
    "        merchant = entry[\"ReceiptInfo\"][\"merchant\"]\n",
    "        items = entry[\"ReceiptInfo\"][\"ITEMS\"]\n",
    "\n",
    "        # Initialize a list to store cleaned descriptions for this entry\n",
    "        cleaned_descriptions = []\n",
    "\n",
    "        # Remove \"number+space\" occurrences in the descriptions and add to the list\n",
    "        for item in items:\n",
    "            description = item.get('description', 'No Description')\n",
    "            cleaned_description = ' '.join(word for word in description.split() if not word.isdigit())\n",
    "            cleaned_descriptions.append(cleaned_description)\n",
    "\n",
    "        # Remove \"UNKNOWN,\" \"<UNKNOWN>,\" and \"unknown\" from the merchant field\n",
    "        merchant = merchant.replace(\"UNKNOWN\", \"\").replace(\"<UNKNOWN>\", \"\").replace(\"unknown\", \"\").replace(\"<>\", \"\")\n",
    "\n",
    "        # Add the merchant and descriptions to the respective lists\n",
    "        merchants.append(merchant)\n",
    "        descriptions.append(cleaned_descriptions)\n",
    "\n",
    "    # Create a DataFrame and save as CSV\n",
    "    entities_df = pd.DataFrame({\n",
    "        'Merchants': merchants, \n",
    "        'Descriptions': descriptions\n",
    "    })\n",
    "    entities_df.to_csv('entities_database.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0bf30229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train, X_test):\n",
    "    clf = KNeighborsClassifier(n_neighbors=20)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return (clf.predict(X_test))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1305d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennifernakano/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Grocery/Supermarkets\", \"Restaurants/Food Services\", \"Clothing/Apparel\", \"Health/Beauty\", \"Electronics/Appliances\", \"Home/Garden\", \"Entertainment/Leisure\"]\n",
    "\n",
    "def getVendorCategory():#listOfItems, Title):\n",
    "    \n",
    "    getReceiptTestData()\n",
    "    \n",
    "    if UPDATEVENDOREMBEDDATABASE:\n",
    "        getVendorEmbeddedDatabase()\n",
    "\n",
    "        \n",
    "    X_train, y_train = getEmbeddedDatabase(f'./embeddedVendorDatabase.csv')\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    merchants = testindDB['Merchants'].to_frame()\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    testindDB['Descriptions'] = testindDB['Descriptions'].apply(lambda lst: ''.join(lst))\n",
    "    testindDB['Merchants'] = testindDB['Merchants'].str.cat(testindDB['Descriptions'], sep=' ')\n",
    "    receiptEmbeddings = convert_to_embeddings_df(testindDB)\n",
    "    X_test = receiptEmbeddings.values\n",
    "    \n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    result_df = pd.concat([merchants, results], axis=1)\n",
    "    return result_df\n",
    "\n",
    "vendorPrediction = getVendorCategory()\n",
    "vendorPrediction.to_csv(\"./VendorCategoryPredictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e4470",
   "metadata": {},
   "source": [
    "# 3) Same thing as 2 but you have to define the categories for the ingredients\n",
    "\n",
    "\n",
    "* Use title of item plus something else (ex: category of vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "df0af313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennifernakano/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "\n",
    "def getProductCategory():#jsonObject, listOfItems, Title):\n",
    "    getReceiptTestData()\n",
    "    \n",
    "    if UPDATEPRODUCTEMBEDDATABASE:\n",
    "        getProductEmbeddedDatabase()\n",
    "        \n",
    "    X_train, y_train = getEmbeddedDatabase(f'./embeddedProductDatabase.csv')\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    merchants = testindDB['Merchants'].to_frame()\n",
    "    testindDB['Descriptions'] = ' '.join(testindDB['Descriptions']) \n",
    "    testindDB['Items'] = testindDB['Merchants'].str.cat(testindDB['Descriptions'], sep=' ')\n",
    "    receiptEmbeddings = convert_to_embeddings_df(testindDB)\n",
    "    X_test = receiptEmbeddings.values\n",
    "    \n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    result_df = pd.concat([merchants, results], axis=1)\n",
    "    return result_df\n",
    "\n",
    "productPrediction = getProductCategory()\n",
    "productPrediction.to_csv(\"./ProductCategoryPredictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1273d48",
   "metadata": {},
   "source": [
    "# 4) Create tests in python\n",
    "\n",
    "* Functions that just test one test and shows that tests passed/failed\n",
    "* At the end shows how many passed and how many failed\n",
    "\n",
    "- Example:\n",
    "\n",
    "     - handleVendor.py\n",
    "     - all test functions tested in testHandleCategory.py (test all the functions in hangleVendor.py) asserts at the end of each test function\n",
    "\n",
    "     - Fixtures in test file: testing all of the things that are needed for the code to run\n",
    "\n",
    "- For part 2, test for:\n",
    "    - If 7 categories, one of the 7 categories and one of the 7 categories\n",
    "    - Edge cases (ex: error in formatting, must be string in list of possible categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
