{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a6085c",
   "metadata": {},
   "source": [
    "# 0) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dcebf",
   "metadata": {},
   "source": [
    "## Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37afca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (0.0.345)\n",
      "Requirement already satisfied: OpenAI in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: torch in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.1,>=0.0.9 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.0.9)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.0.69)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (0.25.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from tqdm>4->OpenAI) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain OpenAI torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4959b784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from jsonschema import validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f0606",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae2821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_RECEIPTS = False # Set this to true if we've added new reciept data in\n",
    "UPDATE_VENDOR_DATABASE = False # Set this to true if we've added more categories/examples to the vendor database\n",
    "UPDATE_PRODUCT_DATABASE = False # Set this to true if we've added more categories/examples to the product database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99e27e",
   "metadata": {},
   "source": [
    "# 1) Use ChatGPT to Convert Receipt Text into Structured JSON\n",
    "\n",
    "* Make sure it generates correct data (use asserts to test all of this)\n",
    "* Make sure edge cases are handled (ex: blank fields, fields not in correct datatype, dollar sign in total, phone number larger than 10 digits)\n",
    "* Prevent language model from returning invalid json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c820a",
   "metadata": {},
   "source": [
    "## Receipts Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c922f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEIPTS_DIR = './receipts/text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bec517",
   "metadata": {},
   "source": [
    "## OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11da93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38501d6c",
   "metadata": {},
   "source": [
    "## ChatGPT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ee6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATGPT_PROMPT = '''Please analyze the provided receipt and extract relevant information to fill in the following structured format:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"(string value)\",\n",
    "    \"address\": \"(string value)\", (split into street address, city, and state)\n",
    "    \"city\": \"(string value)\",\n",
    "    \"state\": \"(string value)\",\n",
    "    \"phoneNumber\": \"(string value)\",\n",
    "    \"tax\": \"(float value)\", (in dollars)\n",
    "    \"total\": \"(float value)\", (in dollars)\n",
    "    \"receiptDate\": \"(string value)\",\n",
    "    \"receiptTime\": \"(string value)\", (if available)\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"(string value)\",\n",
    "        \"quantity\": \"(integer value)\",\n",
    "        \"unitPrice\": \"(float value)\",\n",
    "        \"totalPrice\": \"(float value)\",\n",
    "        \"discountAmount\": \"(float value)\" if any\n",
    "      }, ...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "Remember to check for any discounts or special offers applied to the items and reflect these in the item details. Make sure to end the json object and make sure it's in json format.\n",
    "1. tax, total, unitPrice, totalPrice, discountAmount in float value, and quantity in integer value\n",
    "2. ignore all <UNKNOWN> in the text\n",
    "3. Your response should start with { and end with },\n",
    "4. make sure close all ReceiptInfo and use , to separate different ReceiptInfo\n",
    "\n",
    "example: \"\"\"Marley's Shop\n",
    "123 Long Rd\n",
    "Kailua, HI 67530\n",
    "(808) 555-1234\n",
    "CASHIER: JOHN\n",
    "REGISTER #: 6\n",
    "04/12/2023\n",
    "Transaction ID: 5769009\n",
    "PRICE   QTY  TOTAL\n",
    "APPLES (1 lb)\n",
    "2.99 2 5.98  1001\n",
    "-1.00  999\n",
    "Choco Dream Cookies\n",
    "7.59 1 7.59   1001\n",
    "SUBTOTAL\n",
    "13.57\n",
    "SALES TAX 8.5%\n",
    "1.15\n",
    "TOTAL\n",
    "-14.72\n",
    "VISA CARD            14.72\n",
    "CARD#: **1234\n",
    "REFERENCE#: 6789\n",
    "THANK YOU FOR SHOPPING WITH US!\n",
    "\"\"\"\n",
    "\n",
    "from example should get:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"Marley's Shop\",\n",
    "    \"address\": \"123 Long Rd\",\n",
    "    \"city\": \"Kailua\",\n",
    "    \"state\": \"HI\",\n",
    "    \"phoneNumber\": \"(xxx) xxx-xxxx\",\n",
    "    \"tax\": 1.15,\n",
    "    \"total\": 14.72,\n",
    "    \"receiptDate\": \"04/12/2023\",\n",
    "    \"receiptTime\": \"Transaction ID: 5769009\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"APPLES (1 lb)\",\n",
    "        \"quantity\": 2,\n",
    "        \"unitPrice\": 2.99,\n",
    "        \"totalPrice\": 5.98,\n",
    "        \"discountAmount\": 1.00\n",
    "      },\n",
    "      {\n",
    "        \"description\": \"Choco Dream Cookies\",\n",
    "        \"quantity\": 1,\n",
    "        \"unitPrice\": 7.59,\n",
    "        \"totalPrice\": 7.59,\n",
    "        \"discountAmount\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025a1cd",
   "metadata": {},
   "source": [
    "## Functions to Convert Receipt Text into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6af1c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder_path):\n",
    "    '''\n",
    "    Reads all text files within a folder path.\n",
    " \n",
    "    Parameters:\n",
    "    folder_path (str): The folder path.\n",
    " \n",
    "    Returns:\n",
    "    list[str]: The list of all file names contained at the folder path.\n",
    "    '''\n",
    "    \n",
    "    text_list = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print('Invalid folder path.')\n",
    "        return None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "                text_list.append(file_content) # Append file content as a string to the list\n",
    "                \n",
    "    return text_list\n",
    "\n",
    "def process_and_validate_json(response, schema):\n",
    "    '''\n",
    "    Processes and validates a JSON string.\n",
    " \n",
    "    Parameters:\n",
    "    response (str): The folder path.\n",
    "    schema (dict): The schema to validate against.\n",
    " \n",
    "    Returns:\n",
    "    dict or None: The JSON as a dictionary or None if invalid JSON.\n",
    "    '''\n",
    "    \n",
    "    # Find the index of the first '{'\n",
    "    brace_index = response.find('{')\n",
    "    \n",
    "    # If '{' is found and it's not the first character\n",
    "    if brace_index != -1:\n",
    "        # Extract JSON from the substring starting from the first '{'\n",
    "        extracted_json = response[brace_index:]\n",
    "        \n",
    "        # Validate the extracted JSON against the provided schema\n",
    "        try:\n",
    "            validate(instance=json.loads(extracted_json), schema=schema)\n",
    "            return extracted_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f'Error decoding JSON: {e}')\n",
    "        except ValidationError as e:\n",
    "            print(f'JSON validation error: {e}')\n",
    "    \n",
    "    # Return None if '{' is not found or it's the first character\n",
    "    return None\n",
    "\n",
    "def generate_receipt_json(receipt_text):\n",
    "    '''\n",
    "    Generates a receipt JSON given receipt text using ChatGPT.\n",
    " \n",
    "    Parameters:\n",
    "    receipt_text (str): The text to feed ChatGPT.\n",
    "\n",
    "    Returns:\n",
    "    dict or None: The receipt JSON as a dictionary or None if ChatGPT generates invalid JSON.\n",
    "    '''\n",
    "    \n",
    "    llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0, openai_api_key=OPENAI_API_KEY, max_tokens=1056)\n",
    "    response = llm(receipt_text)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ReceiptInfo\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"merchant\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"state\": {\"type\": \"string\"},\n",
    "                    \"phoneNumber\": {\"type\": \"string\"},\n",
    "                    \"tax\": {\"type\": \"number\"},\n",
    "                    \"total\": {\"type\": \"number\"},\n",
    "                    \"receiptDate\": {\"type\": \"string\"},\n",
    "                    \"ITEMS\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"description\": {\"type\": \"string\"},\n",
    "                                \"quantity\": {\"type\": \"number\"},\n",
    "                                \"unitPrice\": {\"type\": \"number\"},\n",
    "                                \"totalPrice\": {\"type\": \"number\"},\n",
    "                                \"discountAmount\": {\"type\": \"number\"}\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return process_and_validate_json(response, schema)\n",
    "\n",
    "def receipt_texts_to_json_list():\n",
    "    '''\n",
    "    Converts all receipt texts located at RECEIPTS_DIR into a file of a list of JSONs named entities.json.\n",
    "    '''\n",
    "              \n",
    "    output_path = './processed_receipts/receipts.json'\n",
    "\n",
    "    receipts = read_text_files(RECEIPTS_DIR)\n",
    "\n",
    "    receipts_json = []\n",
    "    errorReceipts = []\n",
    "    files_processed = 0\n",
    "    for receipt in receipts:\n",
    "        receipt_json = json.loads(generate_response(CHATGPT_PROMPT + receipt))\n",
    "        receipts_json.append(receipt_json)\n",
    "        files_processed += 1\n",
    "\n",
    "    with open(output_path, 'w') as file:\n",
    "        json.dump(receipts_json, file, indent=4)\n",
    "              \n",
    "def receipts_json_to_csv():\n",
    "    '''\n",
    "    Converts JSON list of receipts stored in entities.json into CSV of only vendor and product descriptions.\n",
    "    '''\n",
    "              \n",
    "    # Read and parse the JSON file\n",
    "    with open('./processed_receipts/receipts.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "              \n",
    "    entry_number = 0\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    merchants = []\n",
    "    descriptions = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for entry in data:\n",
    "        entry_number += 1 \n",
    "        merchant = entry[\"ReceiptInfo\"][\"merchant\"]\n",
    "        items = entry[\"ReceiptInfo\"][\"ITEMS\"]\n",
    "\n",
    "        # Initialize a list to store cleaned descriptions for this entry\n",
    "        cleaned_descriptions = []\n",
    "\n",
    "        # Remove \"number+space\" occurrences in the descriptions and add to the list\n",
    "        for item in items:\n",
    "            description = item.get('description', 'No Description')\n",
    "            cleaned_description = ' '.join(word for word in description.split() if not word.isdigit())\n",
    "            cleaned_descriptions.append(cleaned_description)\n",
    "\n",
    "        # Remove \"UNKNOWN,\" \"<UNKNOWN>,\" and \"unknown\" from the merchant field\n",
    "        merchant = merchant.replace(\"UNKNOWN\", \"\").replace(\"<UNKNOWN>\", \"\").replace(\"unknown\", \"\").replace(\"<>\", \"\")\n",
    "\n",
    "        # Add the merchant and descriptions to the respective lists\n",
    "        merchants.append(merchant)\n",
    "        descriptions.append(cleaned_descriptions)\n",
    "\n",
    "    # Create a DataFrame and save as CSV\n",
    "    entities_df = pd.DataFrame({\n",
    "        'Merchants': merchants, \n",
    "        'Descriptions': descriptions\n",
    "    })\n",
    "    entities_df.to_csv('./processed_receipts/receipts_vendors_products.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a822b3",
   "metadata": {},
   "source": [
    "## Convert all Receipts into a List of JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf8a4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "if UPDATE_RECEIPTS:\n",
    "    receipt_texts_to_json_list()\n",
    "    receipts_json_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e926b32",
   "metadata": {},
   "source": [
    "# 2) Create vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc5ed1",
   "metadata": {},
   "source": [
    "## Load BertTokenizer and BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bf8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2a3ab",
   "metadata": {},
   "source": [
    "## Convert word to embeddings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9e898b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(word):\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling of token embeddings\n",
    "    return embeddings\n",
    "    \n",
    "# Function to convert words in a DataFrame column to embeddings\n",
    "def convert_to_embeddings_df(df):\n",
    "    embeddings = [generate_embeddings(x) for x in df.iloc[:, 0]] \n",
    "    dfs = []\n",
    "    for embedding in embeddings:\n",
    "        dfs.append(pd.DataFrame(embedding))\n",
    "    return pd.concat(dfs)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551cbd1",
   "metadata": {},
   "source": [
    "## Create vector database for vendors and output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1e36e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVendorEmbeddedDatabase():    \n",
    "    folder_path = './vendor database/' \n",
    "    vendorDatabase = pd.DataFrame()\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        category = file.split('/')[-1]\n",
    "        category_name = category.split('_')[0]\n",
    "        newCategory = pd.read_csv(file, encoding='latin-1')\n",
    "        newColumn = convert_to_embeddings_df(newCategory)\n",
    "        newColumn['Category'] = category_name\n",
    "        vendorDatabase = pd.concat([vendorDatabase, newColumn], ignore_index=True, axis=0)\n",
    "    vendorDatabase.to_csv(\"./embeddedVendorDatabase.csv\")\n",
    "\n",
    "        \n",
    "    return vendorDatabase\n",
    "\n",
    "if UPDATEVENDOREMBEDDATABASE:\n",
    "    getVendorEmbeddedDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d761f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductEmbeddedDatabase():\n",
    "\n",
    "    # Directory path containing subfolders with product CSV files\n",
    "    root_folder = './product database/'\n",
    "    productDatabase = pd.DataFrame()\n",
    "\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                # Get the absolute path of the CSV file\n",
    "                csv_file_path = os.path.join(root, file)\n",
    "                category = csv_file_path.split('/')[3]\n",
    "                index = category.find('_database.csv')\n",
    "                category_name = category[:index]                \n",
    "                newCategory = pd.read_csv(csv_file_path, encoding='latin-1')\n",
    "                newColumn = convert_to_embeddings_df(newCategory)\n",
    "                newColumn['Category'] = category_name\n",
    "                productDatabase = pd.concat([productDatabase, newColumn], ignore_index=True, axis=0)\n",
    "    productDatabase.to_csv(\"./embeddedProductDatabase.csv\")\n",
    "\n",
    "        \n",
    "    return productDatabase\n",
    "\n",
    "if UPDATEPRODUCTEMBEDDATABASE:\n",
    "    getProductEmbeddedDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90e4f4",
   "metadata": {},
   "source": [
    "## Split vector database into X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bdcc3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddedDatabase(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    # Creating variables from database values\n",
    "    X = df.drop('Category', axis=1)\n",
    "    y = df['Category']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0bf30229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train, X_test):\n",
    "    clf = KNeighborsClassifier(n_neighbors=20)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return (clf.predict(X_test))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1305d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennifernakano/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#categories = [\"Grocery/Supermarkets\", \"Restaurants/Food Services\", \"Clothing/Apparel\", \"Health/Beauty\", \"Electronics/Appliances\", \"Home/Garden\", \"Entertainment/Leisure\"]\n",
    "\n",
    "def getVendorCategory():#listOfItems, Title):\n",
    "    \n",
    "    getReceiptTestData()\n",
    "    \n",
    "    if UPDATEVENDOREMBEDDATABASE:\n",
    "        getVendorEmbeddedDatabase()\n",
    "\n",
    "        \n",
    "    X_train, y_train = getEmbeddedDatabase(f'./embeddedVendorDatabase.csv')\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    merchants = testindDB['Merchants'].to_frame()\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    testindDB['Descriptions'] = testindDB['Descriptions'].apply(lambda lst: ''.join(lst))\n",
    "    testindDB['Merchants'] = testindDB['Merchants'].str.cat(testindDB['Descriptions'], sep=' ')\n",
    "    receiptEmbeddings = convert_to_embeddings_df(testindDB)\n",
    "    X_test = receiptEmbeddings.values\n",
    "    \n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    result_df = pd.concat([merchants, results], axis=1)\n",
    "    return result_df\n",
    "\n",
    "vendorPrediction = getVendorCategory()\n",
    "vendorPrediction.to_csv(\"./VendorCategoryPredictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e4470",
   "metadata": {},
   "source": [
    "# 3) Same thing as 2 but you have to define the categories for the ingredients\n",
    "\n",
    "\n",
    "* Use title of item plus something else (ex: category of vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "df0af313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennifernakano/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_list(row):\n",
    "    X_test = []\n",
    "    items = []\n",
    "    for item in row['Descriptions']:\n",
    "        X_test.append(item + \" \" + row['Merchants'])\n",
    "        items.append(item)\n",
    "    return X_test, items\n",
    "        \n",
    "\n",
    "def getProductCategory():#jsonObject, listOfItems, Title):\n",
    "    getReceiptTestData()\n",
    "    \n",
    "    if UPDATEPRODUCTEMBEDDATABASE:\n",
    "        getProductEmbeddedDatabase()\n",
    "    \n",
    "    X_train, y_train = getEmbeddedDatabase(f'./embeddedProductDatabase.csv')\n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")    \n",
    "\n",
    "    \n",
    "    testindDB['Descriptions'] = testindDB['Descriptions'].apply(eval) \n",
    "    testindDB = testindDB.apply(process_list, axis=1)\n",
    "    \n",
    "    X_test = [item[0] for item in testindDB]\n",
    "    items = [item[1] for item in testindDB]\n",
    "    \n",
    "\n",
    "    receiptItems = []\n",
    "    merchantItems=[]\n",
    "    for i, product in enumerate(items):\n",
    "        product = items[i]\n",
    "        for item in product:\n",
    "            receiptItems.append(item)\n",
    "        for merchItem in X_test[i]:\n",
    "            merchantItems.append(merchItem)\n",
    "    \n",
    "\n",
    "    X_test = pd.DataFrame(merchantItems)\n",
    "    receiptEmbeddings = convert_to_embeddings_df(X_test)\n",
    "    X_test = receiptEmbeddings.values\n",
    "\n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    receiptItems = pd.DataFrame(receiptItems)\n",
    "    result_df = pd.concat([receiptItems, results], axis=1)\n",
    "    return result_df\n",
    "\n",
    "productPrediction = getProductCategory()\n",
    "productPrediction.to_csv(\"./ProductCategoryPredictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1273d48",
   "metadata": {},
   "source": [
    "# 4) Create tests in python\n",
    "\n",
    "* Functions that just test one test and shows that tests passed/failed\n",
    "* At the end shows how many passed and how many failed\n",
    "\n",
    "- Example:\n",
    "\n",
    "     - handleVendor.py\n",
    "     - all test functions tested in testHandleCategory.py (test all the functions in hangleVendor.py) asserts at the end of each test function\n",
    "\n",
    "     - Fixtures in test file: testing all of the things that are needed for the code to run\n",
    "\n",
    "- For part 2, test for:\n",
    "    - If 7 categories, one of the 7 categories and one of the 7 categories\n",
    "    - Edge cases (ex: error in formatting, must be string in list of possible categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
