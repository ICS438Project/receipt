{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37afca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install langchain OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4959b784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "from jsonschema import validate\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99e27e",
   "metadata": {},
   "source": [
    "# 1) Convert Text to Structured Data\n",
    "\n",
    "* Making sure it generates correct data (use asserts to test all of this)\n",
    "* Making sure you handle edge cases (ex: blank fields, fields not in correct datatype, dollar sign in total, phone number larger than 10 digits)\n",
    "* Language model returning text or invalid json (if not using methos used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11da93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb751f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text):\n",
    "  llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0, openai_api_key=openai_api_key, max_tokens=800)\n",
    "  return llm(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0def54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: edit these for our project\n",
    "def find_span(text, entity_text):\n",
    "    start = text.find(entity_text)\n",
    "    if start == -1:\n",
    "        return None\n",
    "    end = start + len(entity_text)\n",
    "    return (start, end), entity_text\n",
    "\n",
    "def convert_to_prodigy_spans(receipt_text, entities):\n",
    "    text_vals = []\n",
    "    entities = json.loads(entities)\n",
    "    prodigy_data = []\n",
    "    receipt_info = entities[\"ReceiptInfo\"]\n",
    "\n",
    "    for label, entity_text in [\n",
    "        (\"MERCHANT\", receipt_info[\"merchant\"]),\n",
    "        (\"ADDRESS\", receipt_info[\"address\"]),\n",
    "        (\"CITY\", receipt_info[\"city\"]),\n",
    "        (\"STATE\", receipt_info[\"state\"]),\n",
    "        (\"PHONE\", receipt_info[\"phoneNumber\"]),\n",
    "        (\"TAX\", str(receipt_info[\"tax\"])),\n",
    "        (\"TOTAL\", str(receipt_info[\"total\"])),\n",
    "        (\"DATE\", receipt_info[\"receiptDate\"])\n",
    "    ]:\n",
    "        span, text = find_span(receipt_text, entity_text)\n",
    "        text_vals.append(text)\n",
    "        if span:\n",
    "            start, end = span\n",
    "            prodigy_data.append({\"start\": start, \"end\": end, \"label\": label})\n",
    "\n",
    "    # Process item-level entities\n",
    "    for item in receipt_info[\"ITEMS\"]:\n",
    "        for label, entity_text in [\n",
    "            (\"ITEM_DESC\", item[\"description\"]),\n",
    "            (\"QTY\", str(item[\"quantity\"])),\n",
    "            (\"UNIT_PRICE\", str(item[\"unitPrice\"])),\n",
    "            (\"TOTAL_PRICE\", str(item[\"totalPrice\"])),\n",
    "            (\"DISCOUNT\", str(item.get(\"discountAmount\", \"\")))  # Discount might not always be present\n",
    "        ]:\n",
    "            if entity_text:  # Check if the entity text is not empty\n",
    "                span = find_span(receipt_text, entity_text)\n",
    "                if span:\n",
    "                    start, end = span\n",
    "                    prodigy_data.append({\"start\": start, \"end\": end, \"label\": label})\n",
    "\n",
    "    return prodigy_data, text_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498a542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Please analyze the provided receipt and extract relevant information to fill in the following structured format:\n",
    "\n",
    "Merchant Name\n",
    "Address (split into street address, city, and state)\n",
    "Phone Number (masked for privacy as '(xxx) xxx-xxxx')\n",
    "Tax Amount (in dollars)\n",
    "Total Amount (in dollars)\n",
    "Date of the Receipt\n",
    "Time of the Receipt (if available)\n",
    "List of Items, for each item include:\n",
    "Description\n",
    "Quantity\n",
    "Unit Price\n",
    "Total Price\n",
    "Discount Amount (if any)\n",
    "Remember to check for any discounts or special offers applied to the items and reflect these in the item details. Ensure the total amount reflects any discounts or taxes applied. If the receipt has a membership number or any other sensitive personal information, please omit it for privacy reasons.\n",
    "\n",
    "\n",
    "example: \"\"\"Marley's Shop\n",
    "123 Long Rd\n",
    "Kailua, HI 67530\n",
    "(808) 555-1234\n",
    "CASHIER: JOHN\n",
    "REGISTER #: 6\n",
    "04/12/2023\n",
    "Transaction ID: 5769009\n",
    "PRICE   QTY  TOTAL\n",
    "APPLES (1 lb)\n",
    "2.99 2 5.98  1001\n",
    "-1.00  999\n",
    "Choco Dream Cookies\n",
    "7.59 1 7.59   1001\n",
    "SUBTOTAL\n",
    "13.57\n",
    "SALES TAX 8.5%\n",
    "1.15\n",
    "TOTAL\n",
    "-14.72\n",
    "VISA CARD            14.72\n",
    "CARD#: **1234\n",
    "REFERENCE#: 6789\n",
    "THANK YOU FOR SHOPPING WITH US!\n",
    "\"\"\"\n",
    "\n",
    "from example should get:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"Marley's Shop\",\n",
    "    \"address\": \"123 Long Rd\",\n",
    "    \"city\": \"Kailua\",\n",
    "    \"state\": \"HI\",\n",
    "    \"phoneNumber\": \"(xxx) xxx-xxxx\",\n",
    "    \"tax\": 1.15,\n",
    "    \"total\": 14.72,\n",
    "    \"receiptDate\": \"04/12/2023\",\n",
    "    \"receiptTime\": \"Transaction ID: 5769009\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"APPLES (1 lb)\",\n",
    "        \"quantity\": 2,\n",
    "        \"unitPrice\": 2.99,\n",
    "        \"totalPrice\": 5.98,\n",
    "        \"discountAmount\": 1.00\n",
    "      },\n",
    "      {\n",
    "        \"description\": \"Choco Dream Cookies\",\n",
    "        \"quantity\": 1,\n",
    "        \"unitPrice\": 7.59,\n",
    "        \"totalPrice\": 7.59,\n",
    "        \"discountAmount\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "structure = '''\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"(string value)\",\n",
    "    \"address\": \"(string value)\",\n",
    "    \"city\": \"(string value)\",\n",
    "    \"state\": \"(string value)\",\n",
    "    \"phoneNumber\": \"(string value)\",\n",
    "    \"tax\": \"(float value)\",\n",
    "    \"total\": \"(float value)\",\n",
    "    \"receiptDate\": \"(string value)\",\n",
    "    \"receiptTime\": \"(string value)\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"(string value)\",\n",
    "        \"quantity\": \"(integer value)\",\n",
    "        \"unitPrice\": \"(float value)\",\n",
    "        \"totalPrice\": \"(float value)\",\n",
    "        \"discountAmount\": \"(float value)\"\n",
    "      }, ...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404936ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Please analyze the provided receipt and extract relevant information to fill in the following structured format:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"(string value)\",\n",
    "    \"address\": \"(string value)\", (split into street address, city, and state)\n",
    "    \"city\": \"(string value)\",\n",
    "    \"state\": \"(string value)\",\n",
    "    \"phoneNumber\": \"(string value)\",\n",
    "    \"tax\": \"(float value)\", (in dollars)\n",
    "    \"total\": \"(float value)\", (in dollars)\n",
    "    \"receiptDate\": \"(string value)\",\n",
    "    \"receiptTime\": \"(string value)\", (if available)\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"(string value)\",\n",
    "        \"quantity\": \"(integer value)\",\n",
    "        \"unitPrice\": \"(float value)\",\n",
    "        \"totalPrice\": \"(float value)\",\n",
    "        \"discountAmount\": \"(float value)\" if any\n",
    "      }, ...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "Remember to check for any discounts or special offers applied to the items and reflect these in the item details. Make sure to end the json object and make sure it's in json format.\n",
    "\n",
    "\n",
    "example: \"\"\"Marley's Shop\n",
    "123 Long Rd\n",
    "Kailua, HI 67530\n",
    "(808) 555-1234\n",
    "CASHIER: JOHN\n",
    "REGISTER #: 6\n",
    "04/12/2023\n",
    "Transaction ID: 5769009\n",
    "PRICE   QTY  TOTAL\n",
    "APPLES (1 lb)\n",
    "2.99 2 5.98  1001\n",
    "-1.00  999\n",
    "Choco Dream Cookies\n",
    "7.59 1 7.59   1001\n",
    "SUBTOTAL\n",
    "13.57\n",
    "SALES TAX 8.5%\n",
    "1.15\n",
    "TOTAL\n",
    "-14.72\n",
    "VISA CARD            14.72\n",
    "CARD#: **1234\n",
    "REFERENCE#: 6789\n",
    "THANK YOU FOR SHOPPING WITH US!\n",
    "\"\"\"\n",
    "\n",
    "from example should get:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"Marley's Shop\",\n",
    "    \"address\": \"123 Long Rd\",\n",
    "    \"city\": \"Kailua\",\n",
    "    \"state\": \"HI\",\n",
    "    \"phoneNumber\": \"(xxx) xxx-xxxx\",\n",
    "    \"tax\": 1.15,\n",
    "    \"total\": 14.72,\n",
    "    \"receiptDate\": \"04/12/2023\",\n",
    "    \"receiptTime\": \"Transaction ID: 5769009\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"APPLES (1 lb)\",\n",
    "        \"quantity\": 2,\n",
    "        \"unitPrice\": 2.99,\n",
    "        \"totalPrice\": 5.98,\n",
    "        \"discountAmount\": 1.00\n",
    "      },\n",
    "      {\n",
    "        \"description\": \"Choco Dream Cookies\",\n",
    "        \"quantity\": 1,\n",
    "        \"unitPrice\": 7.59,\n",
    "        \"totalPrice\": 7.59,\n",
    "        \"discountAmount\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af1c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder_path):\n",
    "    text_list = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path.\")\n",
    "        return None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "                text_list.append(file_content)  # Append file content as a string to the list\n",
    "                \n",
    "    return text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba202c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 1 minute... for poor people\n",
      "Pausing for 1 minute... for poor people\n",
      "Pausing for 1 minute... for poor people\n",
      "Pausing for 1 minute... for poor people\n"
     ]
    }
   ],
   "source": [
    "folder_path = './receipts/text'\n",
    "resulting_receipts = read_text_files(folder_path)\n",
    "file_path = f'./entities.json'\n",
    "entitiesList = []\n",
    "files_processed = 0\n",
    "for receipt_text in resulting_receipts: \n",
    "    entities = generate_response(prompt + receipt_text)\n",
    "    #print(entities)\n",
    "    jsonObject = json.loads(entities)\n",
    "    entitiesList.append(jsonObject)\n",
    "    files_processed += 1\n",
    "    \n",
    "    if files_processed % 3 == 0:\n",
    "        print(\"Pausing for 1 minute... for poor people\")\n",
    "        time.sleep(60)\n",
    "    \n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(entitiesList, file, indent=4)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536f2f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Example NER Usage\\nprodigy_spans_true, text_vals = convert_to_prodigy_spans(receipt_text, entities)\\nprint(json.dumps(prodigy_spans_true, indent=2))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Example NER Usage\n",
    "prodigy_spans_true, text_vals = convert_to_prodigy_spans(receipt_text, entities)\n",
    "print(json.dumps(prodigy_spans_true, indent=2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e926b32",
   "metadata": {},
   "source": [
    "# 2) Identify category for vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ee8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateInput(entities):\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ReceiptInfo\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"merchant\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"state\": {\"type\": \"string\"},\n",
    "                    \"phoneNumber\": {\"type\": \"string\"},\n",
    "                    \"tax\": {\"type\": \"number\"},\n",
    "                    \"total\": {\"type\": \"number\"},\n",
    "                    \"receiptDate\": {\"type\": \"string\"},\n",
    "                    \"ITEMS\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"description\": {\"type\": \"string\"},\n",
    "                                \"quantity\": {\"type\": \"number\"},\n",
    "                                \"unitPrice\": {\"type\": \"number\"},\n",
    "                                \"totalPrice\": {\"type\": \"number\"},\n",
    "                                \"discountAmount\": {\"type\": \"number\"}\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    validate(instance=json.loads(entities), schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9bf8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e898b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(word):\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling of token embeddings\n",
    "    return embeddings\n",
    "    \n",
    "# Function to convert words in a DataFrame column to embeddings\n",
    "def convert_to_embeddings_df(df):\n",
    "    embeddings = [generate_embeddings(x) for x in df.iloc[:, 0]] # was initally df[\"Items\"]\n",
    "    dfs = []\n",
    "    for embedding in embeddings:\n",
    "        dfs.append(pd.DataFrame(embedding))\n",
    "    return pd.concat(dfs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e36e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting word databases to a embedding database\n",
    "clothing_db = pd.read_csv(\"clothing_datebase.csv\")\n",
    "clothing_df = convert_to_embeddings_df(clothing_db)\n",
    "clothing_df['Category'] = 'Clothing'\n",
    "\n",
    "electronics_db = pd.read_csv(\"electronics_datebase.csv\")\n",
    "electronics_df = convert_to_embeddings_df(clothing_db)\n",
    "electronics_df['Category'] = 'Electronics'\n",
    "\n",
    "entertainment_db = pd.read_csv(\"entertainment_datebase.csv\")\n",
    "entertainment_df = convert_to_embeddings_df(entertainment_db)\n",
    "entertainment_df['Category'] = 'Entertainment'\n",
    "\n",
    "foodService_db = pd.read_csv(\"food_service_datebase.csv\")\n",
    "foodService_df = convert_to_embeddings_df(foodService_db)\n",
    "foodService_df['Category'] = 'Food Service'\n",
    "\n",
    "grocery_db = pd.read_csv(\"grocery_datebase.csv\")\n",
    "grocery_df = convert_to_embeddings_df(grocery_db)\n",
    "grocery_df['Category'] = 'Grocery'\n",
    "\n",
    "healthBeauty_db = pd.read_csv(\"health_beauty_datebase.csv\")\n",
    "healthBeauty_df = convert_to_embeddings_df(healthBeauty_db)\n",
    "healthBeauty_df['Category'] = 'Health Beauty'\n",
    "\n",
    "homeGarden_db = pd.read_csv(\"home_garden_datebase.csv\")\n",
    "homeGarden_df = convert_to_embeddings_df(homeGarden_db)\n",
    "homeGarden_df['Category'] = 'Home Garden'\n",
    "\n",
    "embeddedDatabase = pd.concat([clothing_df, electronics_df, entertainment_df, foodService_df, grocery_df, healthBeauty_df, homeGarden_df], axis=0)\n",
    "embeddedDatabase.to_csv(\"embeddedDatabase.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f960230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchInDatabase():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdcc3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddedDatabase():\n",
    "    filePath = f'./embeddedDatabase.csv'\n",
    "    df = pd.read_csv(filePath)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    # Creating variables from database values\n",
    "    X = df.drop('Category', axis=1)\n",
    "    y = df['Category']\n",
    "    \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce32009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReceiptTestData():\n",
    "    # Read and parse the JSON file\n",
    "    with open('./entities.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # Initialize variables\n",
    "    entry_number = 0\n",
    "    current_merchant = None\n",
    "\n",
    "    # Initialize a list to store the processed entries as dictionaries\n",
    "    processed_entries = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for entry in data:\n",
    "        entry_number += 1  # Increment the entry number\n",
    "        merchant = entry[\"ReceiptInfo\"][\"merchant\"]\n",
    "        items = entry[\"ReceiptInfo\"][\"ITEMS\"]\n",
    "\n",
    "        # Remove \"number+space\" occurrences in the descriptions and combine them\n",
    "        cleaned_descriptions = []\n",
    "        for item in items:\n",
    "            description = item.get('description', 'No Description')\n",
    "            cleaned_description = ' '.join(word for word in description.split() if not word.isdigit())\n",
    "            cleaned_descriptions.append(cleaned_description)\n",
    "\n",
    "        # Combine descriptions with spaces\n",
    "        combined_descriptions = ' '.join(cleaned_descriptions)\n",
    "\n",
    "        # Remove \"UNKNOWN,\" \"<UNKNOWN>,\" and \"unknown\" from the merchant field\n",
    "        merchant = merchant.replace(\"UNKNOWN\", \"\").replace(\"<UNKNOWN>\", \"\").replace(\"unknown\", \"\").replace(\"<>\", \"\")\n",
    "\n",
    "        # Remove \"UNKNOWN,\" \"<UNKNOWN>,\" and \"unknown\" from the combined_descriptions field\n",
    "        combined_descriptions = combined_descriptions.replace(\"UNKNOWN\", \"\").replace(\"<UNKNOWN>\", \"\").replace(\"unknown\", \"\").replace(\"<>\", \"\")\n",
    "\n",
    "        # Create a dictionary for the current entry\n",
    "        entry_dict = {\n",
    "            \"entry_number\": entry_number,\n",
    "            \"merchant\": merchant,\n",
    "            \"combined_descriptions\": combined_descriptions\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        processed_entries.append(entry_dict)\n",
    "    \n",
    "    '''\n",
    "    # Display the processed entries as dictionaries\n",
    "    for entry in processed_entries:\n",
    "        print(entry)\n",
    "    '''\n",
    "    merchants = []\n",
    "    descriptions = []\n",
    "\n",
    "    for entry in processed_entries:\n",
    "        merchant = entry[\"merchant\"]\n",
    "        description = entry[\"combined_descriptions\"]\n",
    "        merchants.append(merchant)\n",
    "        descriptions.append(description)\n",
    "        \n",
    "    entities_df = pd.DataFrame({\n",
    "    'Merchants': merchants, \n",
    "    'Descriptions': descriptions\n",
    "    })\n",
    "    entities_df.to_csv('entities_database.csv', index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bf30229",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#return clf.predict(generate_embeddings(\"Nike\"))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clf\u001b[38;5;241m.\u001b[39mpredict(receiptEmbeddings)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(KNN())\n",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m, in \u001b[0;36mKNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m testindDB \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities_database.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m testindDB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcatenated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m testindDB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMerchants\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcat(testindDB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescriptions\u001b[39m\u001b[38;5;124m'\u001b[39m], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m receiptEmbeddings \u001b[38;5;241m=\u001b[39m convert_to_embeddings_df(testindDB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcatenated\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#return clf.predict(generate_embeddings(\"Nike\"))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clf\u001b[38;5;241m.\u001b[39mpredict(receiptEmbeddings)\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mconvert_to_embeddings_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_embeddings_df\u001b[39m(df):\n\u001b[0;32m---> 10\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [generate_embeddings(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItems\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     11\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Items'"
     ]
    }
   ],
   "source": [
    "def KNN():\n",
    "    X_train, y_train = getEmbeddedDatabase()\n",
    "\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    testindDB = pd.read_csv(\"entities_database.csv\")\n",
    "    testindDB['Concatenated'] = testindDB['Merchants'].str.cat(testindDB['Descriptions'], sep='')\n",
    "    receiptEmbeddings = convert_to_embeddings_df(testindDB['Concatenated'])\n",
    "\n",
    "    \n",
    "    \n",
    "    #return clf.predict(generate_embeddings(\"Nike\"))\n",
    "    return clf.predict(receiptEmbeddings)\n",
    "\n",
    "print(KNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1305d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Grocery/Supermarkets\", \"Restaurants/Food Services\", \"Clothing/Apparel\", \"Health/Beauty\", \"Electronics/Appliances\", \"Home/Garden\", \"Entertainment/Leisure\"]\n",
    "\n",
    "def getVendorCategory(listOfItems, Title):\n",
    "    #validateInput()\n",
    "    #convertToEmbeddings()\n",
    "    #seachInDatabase()\n",
    "    #takeMajority()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e4470",
   "metadata": {},
   "source": [
    "# 3) Same thing as 2 but you have to define the categories for the ingredients\n",
    "\n",
    "\n",
    "* Use title of item plus something else (ex: category of vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0af313",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "def getVendorCategory(jsonObject, listOfItems, Title):\n",
    "    #validateInput(jsonObject)\n",
    "    #convertToEmbeddings()\n",
    "    #seachInDatabase()\n",
    "    #takeMajority()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1273d48",
   "metadata": {},
   "source": [
    "# 4) Create tests in python\n",
    "\n",
    "* Functions that just test one test and shows that tests passed/failed\n",
    "* At the end shows how many passed and how many failed\n",
    "\n",
    "- Example:\n",
    "\n",
    "     - handleVendor.py\n",
    "     - all test functions tested in testHandleCategory.py (test all the functions in hangleVendor.py) asserts at the end of each test function\n",
    "\n",
    "     - Fixtures in test file: testing all of the things that are needed for the code to run\n",
    "\n",
    "- For part 2, test for:\n",
    "    - If 7 categories, one of the 7 categories and one of the 7 categories\n",
    "    - Edge cases (ex: error in formatting, must be string in list of possible categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83bde9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
