{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a6085c",
   "metadata": {},
   "source": [
    "# 0) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dcebf",
   "metadata": {},
   "source": [
    "## Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37afca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (0.0.345)\n",
      "Requirement already satisfied: OpenAI in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: torch in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.1,>=0.0.9 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.0.9)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (0.0.69)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (0.25.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from OpenAI) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from tqdm>4->OpenAI) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ggaav\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4959b784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from jsonschema import validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f0606",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae2821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_RECEIPTS = False # Set this to true if we've added new reciept data in\n",
    "UPDATE_VENDOR_DATABASE = False # Set this to true if we've added more categories/examples to the vendor database\n",
    "UPDATE_PRODUCT_DATABASE = False # Set this to true if we've added more categories/examples to the product database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99e27e",
   "metadata": {},
   "source": [
    "# 1) Use ChatGPT to Convert Receipt Text into Structured JSON\n",
    "\n",
    "* Make sure it generates correct data (use asserts to test all of this)\n",
    "* Make sure edge cases are handled (ex: blank fields, fields not in correct datatype, dollar sign in total, phone number larger than 10 digits)\n",
    "* Prevent language model from returning invalid json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c820a",
   "metadata": {},
   "source": [
    "## Receipts Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c922f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEIPTS_INPUT = './receipts/text'\n",
    "RECEIPTS_OUTPUT = './processed_receipts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bec517",
   "metadata": {},
   "source": [
    "## OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11da93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38501d6c",
   "metadata": {},
   "source": [
    "## ChatGPT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ee6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATGPT_PROMPT = '''Please analyze the provided receipt and extract relevant information to fill in the following structured format:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"(string value)\",\n",
    "    \"address\": \"(string value)\", (split into street address, city, and state)\n",
    "    \"city\": \"(string value)\",\n",
    "    \"state\": \"(string value)\",\n",
    "    \"phoneNumber\": \"(string value)\",\n",
    "    \"tax\": \"(float value)\", (in dollars)\n",
    "    \"total\": \"(float value)\", (in dollars)\n",
    "    \"receiptDate\": \"(string value)\",\n",
    "    \"receiptTime\": \"(string value)\", (if available)\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"(string value)\",\n",
    "        \"quantity\": \"(integer value)\",\n",
    "        \"unitPrice\": \"(float value)\",\n",
    "        \"totalPrice\": \"(float value)\",\n",
    "        \"discountAmount\": \"(float value)\" if any\n",
    "      }, ...\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "Remember to check for any discounts or special offers applied to the items and reflect these in the item details. Make sure to end the json object and make sure it's in json format.\n",
    "1. tax, total, unitPrice, totalPrice, discountAmount in float value, and quantity in integer value\n",
    "2. ignore all <UNKNOWN> in the text\n",
    "3. Your response should start with { and end with },\n",
    "4. make sure close all ReceiptInfo and use , to separate different ReceiptInfo\n",
    "\n",
    "example: \"\"\"Marley's Shop\n",
    "123 Long Rd\n",
    "Kailua, HI 67530\n",
    "(808) 555-1234\n",
    "CASHIER: JOHN\n",
    "REGISTER #: 6\n",
    "04/12/2023\n",
    "Transaction ID: 5769009\n",
    "PRICE   QTY  TOTAL\n",
    "APPLES (1 lb)\n",
    "2.99 2 5.98  1001\n",
    "-1.00  999\n",
    "Choco Dream Cookies\n",
    "7.59 1 7.59   1001\n",
    "SUBTOTAL\n",
    "13.57\n",
    "SALES TAX 8.5%\n",
    "1.15\n",
    "TOTAL\n",
    "-14.72\n",
    "VISA CARD            14.72\n",
    "CARD#: **1234\n",
    "REFERENCE#: 6789\n",
    "THANK YOU FOR SHOPPING WITH US!\n",
    "\"\"\"\n",
    "\n",
    "from example should get:\n",
    "{\n",
    "  \"ReceiptInfo\": {\n",
    "    \"merchant\": \"Marley's Shop\",\n",
    "    \"address\": \"123 Long Rd\",\n",
    "    \"city\": \"Kailua\",\n",
    "    \"state\": \"HI\",\n",
    "    \"phoneNumber\": \"(xxx) xxx-xxxx\",\n",
    "    \"tax\": 1.15,\n",
    "    \"total\": 14.72,\n",
    "    \"receiptDate\": \"04/12/2023\",\n",
    "    \"receiptTime\": \"Transaction ID: 5769009\",\n",
    "    \"ITEMS\": [\n",
    "      {\n",
    "        \"description\": \"APPLES (1 lb)\",\n",
    "        \"quantity\": 2,\n",
    "        \"unitPrice\": 2.99,\n",
    "        \"totalPrice\": 5.98,\n",
    "        \"discountAmount\": 1.00\n",
    "      },\n",
    "      {\n",
    "        \"description\": \"Choco Dream Cookies\",\n",
    "        \"quantity\": 1,\n",
    "        \"unitPrice\": 7.59,\n",
    "        \"totalPrice\": 7.59,\n",
    "        \"discountAmount\": 0\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025a1cd",
   "metadata": {},
   "source": [
    "## Functions to Convert Receipt Text into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6af1c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder_path):\n",
    "    '''\n",
    "    Reads all text files within a folder path.\n",
    " \n",
    "    Parameters:\n",
    "    folder_path (str): The folder path.\n",
    " \n",
    "    Returns:\n",
    "    list[str]: The list of all file names contained at the folder path.\n",
    "    '''\n",
    "    \n",
    "    text_list = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print('Invalid folder path.')\n",
    "        return None\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "                text_list.append(file_content) # Append file content as a string to the list\n",
    "                \n",
    "    return text_list\n",
    "\n",
    "def process_and_validate_json(response, schema):\n",
    "    '''\n",
    "    Processes and validates a JSON string.\n",
    " \n",
    "    Parameters:\n",
    "    response (str): The folder path.\n",
    "    schema (dict): The schema to validate against.\n",
    " \n",
    "    Returns:\n",
    "    dict or None: The JSON as a dictionary or None if invalid JSON.\n",
    "    '''\n",
    "    \n",
    "    # Find the index of the first '{'\n",
    "    brace_index = response.find('{')\n",
    "    \n",
    "    # If '{' is found and it's not the first character\n",
    "    if brace_index != -1:\n",
    "        # Extract JSON from the substring starting from the first '{'\n",
    "        extracted_json = response[brace_index:]\n",
    "        \n",
    "        # Validate the extracted JSON against the provided schema\n",
    "        try:\n",
    "            validate(instance=json.loads(extracted_json), schema=schema)\n",
    "            return extracted_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f'Error decoding JSON: {e}')\n",
    "        except ValidationError as e:\n",
    "            print(f'JSON validation error: {e}')\n",
    "    \n",
    "    # Return None if '{' is not found or it's the first character\n",
    "    return None\n",
    "\n",
    "def generate_receipt_json(receipt_text):\n",
    "    '''\n",
    "    Generates a receipt JSON given receipt text using ChatGPT.\n",
    " \n",
    "    Parameters:\n",
    "    receipt_text (str): The text to feed ChatGPT.\n",
    "\n",
    "    Returns:\n",
    "    dict or None: The receipt JSON as a dictionary or None if ChatGPT generates invalid JSON.\n",
    "    '''\n",
    "    \n",
    "    llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0, openai_api_key=OPENAI_API_KEY, max_tokens=1056)\n",
    "    response = llm(receipt_text)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ReceiptInfo\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"merchant\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"},\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"state\": {\"type\": \"string\"},\n",
    "                    \"phoneNumber\": {\"type\": \"string\"},\n",
    "                    \"tax\": {\"type\": \"number\"},\n",
    "                    \"total\": {\"type\": \"number\"},\n",
    "                    \"receiptDate\": {\"type\": \"string\"},\n",
    "                    \"ITEMS\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"description\": {\"type\": \"string\"},\n",
    "                                \"quantity\": {\"type\": \"number\"},\n",
    "                                \"unitPrice\": {\"type\": \"number\"},\n",
    "                                \"totalPrice\": {\"type\": \"number\"},\n",
    "                                \"discountAmount\": {\"type\": \"number\"}\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return process_and_validate_json(response, schema)\n",
    "\n",
    "def receipt_texts_to_json_list():\n",
    "    '''\n",
    "    Converts all receipt texts located at RECEIPTS_INPUT into a file of a list of JSONs named entities.json.\n",
    "    '''\n",
    "              \n",
    "    output_path = RECEIPTS_OUTPUT + '/receipts.json'\n",
    "\n",
    "    receipts = read_text_files(RECEIPTS_INPUT)\n",
    "\n",
    "    receipts_json = []\n",
    "    errorReceipts = []\n",
    "    files_processed = 0\n",
    "    for receipt in receipts:\n",
    "        receipt_json = json.loads(generate_response(CHATGPT_PROMPT + receipt))\n",
    "        receipts_json.append(receipt_json)\n",
    "        files_processed += 1\n",
    "\n",
    "    with open(output_path, 'w') as file:\n",
    "        json.dump(receipts_json, file, indent=4)\n",
    "              \n",
    "def receipts_json_to_csv():\n",
    "    '''\n",
    "    Converts JSON list of receipts stored in entities.json into CSV of only vendor and product descriptions.\n",
    "    '''\n",
    "              \n",
    "    # Read and parse the JSON file\n",
    "    with open(RECEIPTS_OUTPUT + '/receipts.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "              \n",
    "    entry_number = 0\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    merchants = []\n",
    "    descriptions = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for entry in data:\n",
    "        entry_number += 1 \n",
    "        merchant = entry[\"ReceiptInfo\"][\"merchant\"]\n",
    "        items = entry[\"ReceiptInfo\"][\"ITEMS\"]\n",
    "\n",
    "        # Initialize a list to store cleaned descriptions for this entry\n",
    "        cleaned_descriptions = []\n",
    "\n",
    "        # Remove \"number+space\" occurrences in the descriptions and add to the list\n",
    "        for item in items:\n",
    "            description = item.get('description', 'No Description')\n",
    "            cleaned_description = ' '.join(word for word in description.split() if not word.isdigit())\n",
    "            cleaned_descriptions.append(cleaned_description)\n",
    "\n",
    "        # Remove \"UNKNOWN,\" \"<UNKNOWN>,\" and \"unknown\" from the merchant field\n",
    "        merchant = merchant.replace(\"UNKNOWN\", \"\").replace(\"<UNKNOWN>\", \"\").replace(\"unknown\", \"\").replace(\"<>\", \"\")\n",
    "\n",
    "        # Add the merchant and descriptions to the respective lists\n",
    "        merchants.append(merchant)\n",
    "        descriptions.append(cleaned_descriptions)\n",
    "\n",
    "    # Create a DataFrame and save as CSV\n",
    "    entities_df = pd.DataFrame({\n",
    "        'Vendors': merchants, \n",
    "        'Products': descriptions\n",
    "    })\n",
    "    entities_df.to_csv(RECEIPTS_OUTPUT + '/vendors_and_products.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a822b3",
   "metadata": {},
   "source": [
    "## Convert all Receipts into a List of JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf8a4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "if UPDATE_RECEIPTS:\n",
    "    receipt_texts_to_json_list()\n",
    "    receipts_json_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e926b32",
   "metadata": {},
   "source": [
    "# 2) Create vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc5ed1",
   "metadata": {},
   "source": [
    "## Load BertTokenizer and BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bf8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-large-en\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2a3ab",
   "metadata": {},
   "source": [
    "## Functions to Convert Word into Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e898b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(word):\n",
    "    '''\n",
    "    Generates a vector of embeddings given a word/sentence.\n",
    " \n",
    "    Parameters:\n",
    "    word (str): The word/sentence.\n",
    "\n",
    "    Returns:\n",
    "    tensor(1, 1024): The vector of embeddings.\n",
    "    '''\n",
    "    \n",
    "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling of token embeddings\n",
    "    return embeddings\n",
    "\n",
    "def convert_to_embeddings_df(df):\n",
    "    '''\n",
    "    Convert words in a DataFrame column to embeddings.\n",
    " \n",
    "    Parameters:\n",
    "    df (dataframe): The dataframe.\n",
    "\n",
    "    Returns:\n",
    "    dataframe: The dataframe of embeddings.\n",
    "    '''\n",
    "    \n",
    "    embeddings = [generate_embeddings(x) for x in df.iloc[:, 0]] \n",
    "    dfs = []\n",
    "    for embedding in embeddings:\n",
    "        dfs.append(pd.DataFrame(embedding))\n",
    "    return pd.concat(dfs)      \n",
    "\n",
    "def create_embedded_vendor_database():\n",
    "    '''\n",
    "    Create vector of embeddings database from vendor word databases. \n",
    "    Outputs to ./databases/vendor/embedding.\n",
    "    '''\n",
    "    \n",
    "    vendor_database = pd.DataFrame()\n",
    "    \n",
    "    csv_files = glob.glob(os.path.join('.', 'databases', 'vendor', 'word', '*.csv'))\n",
    "    for file in csv_files:\n",
    "        category = os.path.split(file)[-1]\n",
    "        category_name = category.replace('.csv', '').replace('_', ' ')\n",
    "        \n",
    "        new_category = pd.read_csv(file, encoding='latin-1')\n",
    "        new_column = convert_to_embeddings_df(new_category)\n",
    "        new_column['Category'] = category_name\n",
    "        \n",
    "        vendor_database = pd.concat([vendor_database, new_column], ignore_index=True, axis=0)\n",
    "    vendor_database.to_csv(\"./databases/vendor/embedding/embedded_vendor_database.csv\")\n",
    "\n",
    "    return vendor_database\n",
    "\n",
    "def create_embedded_product_database():\n",
    "    '''\n",
    "    Create vector of embeddings database from product word databases. \n",
    "    Outputs to ./databases/product/embedding.\n",
    "    '''\n",
    "    \n",
    "    product_database = pd.DataFrame()\n",
    "    \n",
    "    # Loop through subfolders of product CSV files\n",
    "    for root, dirs, files in os.walk(os.path.join('.', 'databases', 'product', 'word')): \n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_file_path = os.path.join(root, file) # Get the absolute path of the CSV file\n",
    "                category = os.path.split(file)[-1]\n",
    "                category_name = category.replace('.csv', '').replace('_', ' ')\n",
    "                \n",
    "                new_category = pd.read_csv(csv_file_path, encoding='latin-1')\n",
    "                new_column = convert_to_embeddings_df(new_category)\n",
    "                new_column['Category'] = category_name\n",
    "                \n",
    "                product_database = pd.concat([product_database, new_column], ignore_index=True, axis=0)\n",
    "    product_database.to_csv('./databases/product/embedding/embedded_product_database.csv')\n",
    "        \n",
    "    return product_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551cbd1",
   "metadata": {},
   "source": [
    "## Create vector database for vendors and output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e36e90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.348148</td>\n",
       "      <td>0.070989</td>\n",
       "      <td>0.345142</td>\n",
       "      <td>0.454322</td>\n",
       "      <td>-0.121698</td>\n",
       "      <td>0.139333</td>\n",
       "      <td>0.355314</td>\n",
       "      <td>0.753187</td>\n",
       "      <td>-0.261246</td>\n",
       "      <td>0.381137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800264</td>\n",
       "      <td>-0.327533</td>\n",
       "      <td>-0.573699</td>\n",
       "      <td>0.923416</td>\n",
       "      <td>0.766704</td>\n",
       "      <td>0.507328</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>-0.253998</td>\n",
       "      <td>-0.419199</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.424691</td>\n",
       "      <td>0.224581</td>\n",
       "      <td>0.082054</td>\n",
       "      <td>0.408848</td>\n",
       "      <td>-0.406745</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.350302</td>\n",
       "      <td>0.555074</td>\n",
       "      <td>-0.245362</td>\n",
       "      <td>0.670662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.823771</td>\n",
       "      <td>-0.275016</td>\n",
       "      <td>-0.711063</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>1.094751</td>\n",
       "      <td>0.322661</td>\n",
       "      <td>-0.243856</td>\n",
       "      <td>-0.151363</td>\n",
       "      <td>-0.110732</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.261775</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>0.319991</td>\n",
       "      <td>0.399557</td>\n",
       "      <td>-0.756488</td>\n",
       "      <td>0.221527</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>0.727009</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>0.481805</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123322</td>\n",
       "      <td>-0.266782</td>\n",
       "      <td>-0.185012</td>\n",
       "      <td>0.873377</td>\n",
       "      <td>1.033490</td>\n",
       "      <td>0.357246</td>\n",
       "      <td>-0.110494</td>\n",
       "      <td>-0.465703</td>\n",
       "      <td>-0.216796</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102913</td>\n",
       "      <td>0.732180</td>\n",
       "      <td>0.253901</td>\n",
       "      <td>0.118898</td>\n",
       "      <td>-0.497602</td>\n",
       "      <td>-0.217534</td>\n",
       "      <td>0.065586</td>\n",
       "      <td>0.408434</td>\n",
       "      <td>0.314015</td>\n",
       "      <td>0.697692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746516</td>\n",
       "      <td>-0.199601</td>\n",
       "      <td>-0.759398</td>\n",
       "      <td>0.627257</td>\n",
       "      <td>0.524419</td>\n",
       "      <td>0.019521</td>\n",
       "      <td>0.155198</td>\n",
       "      <td>-0.285741</td>\n",
       "      <td>0.180573</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.053010</td>\n",
       "      <td>0.078582</td>\n",
       "      <td>-0.070174</td>\n",
       "      <td>0.435813</td>\n",
       "      <td>-0.470824</td>\n",
       "      <td>-0.178367</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>0.778306</td>\n",
       "      <td>-0.329487</td>\n",
       "      <td>0.430396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680812</td>\n",
       "      <td>-0.156575</td>\n",
       "      <td>-0.594988</td>\n",
       "      <td>1.029964</td>\n",
       "      <td>1.230545</td>\n",
       "      <td>0.656802</td>\n",
       "      <td>0.384140</td>\n",
       "      <td>-0.032551</td>\n",
       "      <td>-0.146348</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10046</th>\n",
       "      <td>-0.054424</td>\n",
       "      <td>0.112068</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>0.153556</td>\n",
       "      <td>-0.536033</td>\n",
       "      <td>-0.067400</td>\n",
       "      <td>0.155822</td>\n",
       "      <td>0.722600</td>\n",
       "      <td>-0.014032</td>\n",
       "      <td>0.050964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840893</td>\n",
       "      <td>-0.657955</td>\n",
       "      <td>-0.799695</td>\n",
       "      <td>1.191250</td>\n",
       "      <td>0.453020</td>\n",
       "      <td>0.596119</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>-0.095915</td>\n",
       "      <td>-0.052083</td>\n",
       "      <td>hotel bookings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>-0.197431</td>\n",
       "      <td>0.312596</td>\n",
       "      <td>0.339443</td>\n",
       "      <td>0.233759</td>\n",
       "      <td>-0.311259</td>\n",
       "      <td>-0.376540</td>\n",
       "      <td>0.361626</td>\n",
       "      <td>0.817655</td>\n",
       "      <td>0.271401</td>\n",
       "      <td>-0.204186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699825</td>\n",
       "      <td>-0.475542</td>\n",
       "      <td>-0.819073</td>\n",
       "      <td>1.350083</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.198073</td>\n",
       "      <td>-0.642915</td>\n",
       "      <td>0.407108</td>\n",
       "      <td>0.066086</td>\n",
       "      <td>hotel bookings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10048</th>\n",
       "      <td>0.123539</td>\n",
       "      <td>0.291378</td>\n",
       "      <td>0.071445</td>\n",
       "      <td>0.083885</td>\n",
       "      <td>-0.221297</td>\n",
       "      <td>-0.065850</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>0.595908</td>\n",
       "      <td>0.662541</td>\n",
       "      <td>-0.286881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.695497</td>\n",
       "      <td>-0.829663</td>\n",
       "      <td>-1.079063</td>\n",
       "      <td>1.339037</td>\n",
       "      <td>0.293813</td>\n",
       "      <td>0.480016</td>\n",
       "      <td>-0.927876</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.515470</td>\n",
       "      <td>hotel bookings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10049</th>\n",
       "      <td>-0.252277</td>\n",
       "      <td>0.458106</td>\n",
       "      <td>-0.094561</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>-0.691538</td>\n",
       "      <td>-0.208291</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>0.793264</td>\n",
       "      <td>0.294115</td>\n",
       "      <td>0.431037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313706</td>\n",
       "      <td>-0.804091</td>\n",
       "      <td>-1.230590</td>\n",
       "      <td>1.274414</td>\n",
       "      <td>0.386450</td>\n",
       "      <td>0.689333</td>\n",
       "      <td>-0.483685</td>\n",
       "      <td>-0.168044</td>\n",
       "      <td>-0.327015</td>\n",
       "      <td>hotel bookings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050</th>\n",
       "      <td>-0.182438</td>\n",
       "      <td>0.466301</td>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>-0.393372</td>\n",
       "      <td>0.238236</td>\n",
       "      <td>-0.304918</td>\n",
       "      <td>0.807810</td>\n",
       "      <td>0.545763</td>\n",
       "      <td>-0.284043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652165</td>\n",
       "      <td>-0.622744</td>\n",
       "      <td>-1.115973</td>\n",
       "      <td>0.967440</td>\n",
       "      <td>0.748833</td>\n",
       "      <td>0.857725</td>\n",
       "      <td>-0.198816</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>-0.521847</td>\n",
       "      <td>hotel bookings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10051 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.348148  0.070989  0.345142  0.454322 -0.121698  0.139333  0.355314   \n",
       "1     -0.424691  0.224581  0.082054  0.408848 -0.406745  0.006946  0.350302   \n",
       "2     -0.261775  0.055695  0.319991  0.399557 -0.756488  0.221527  0.518702   \n",
       "3      0.102913  0.732180  0.253901  0.118898 -0.497602 -0.217534  0.065586   \n",
       "4     -0.053010  0.078582 -0.070174  0.435813 -0.470824 -0.178367  0.418519   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10046 -0.054424  0.112068  0.103916  0.153556 -0.536033 -0.067400  0.155822   \n",
       "10047 -0.197431  0.312596  0.339443  0.233759 -0.311259 -0.376540  0.361626   \n",
       "10048  0.123539  0.291378  0.071445  0.083885 -0.221297 -0.065850  0.581829   \n",
       "10049 -0.252277  0.458106 -0.094561  0.027453 -0.691538 -0.208291  0.034833   \n",
       "10050 -0.182438  0.466301  0.195577  0.004715 -0.393372  0.238236 -0.304918   \n",
       "\n",
       "              7         8         9  ...      1015      1016      1017  \\\n",
       "0      0.753187 -0.261246  0.381137  ... -0.800264 -0.327533 -0.573699   \n",
       "1      0.555074 -0.245362  0.670662  ... -0.823771 -0.275016 -0.711063   \n",
       "2      0.727009  0.019079  0.481805  ... -1.123322 -0.266782 -0.185012   \n",
       "3      0.408434  0.314015  0.697692  ... -0.746516 -0.199601 -0.759398   \n",
       "4      0.778306 -0.329487  0.430396  ... -0.680812 -0.156575 -0.594988   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10046  0.722600 -0.014032  0.050964  ... -0.840893 -0.657955 -0.799695   \n",
       "10047  0.817655  0.271401 -0.204186  ... -0.699825 -0.475542 -0.819073   \n",
       "10048  0.595908  0.662541 -0.286881  ... -0.695497 -0.829663 -1.079063   \n",
       "10049  0.793264  0.294115  0.431037  ... -0.313706 -0.804091 -1.230590   \n",
       "10050  0.807810  0.545763 -0.284043  ... -0.652165 -0.622744 -1.115973   \n",
       "\n",
       "           1018      1019      1020      1021      1022      1023  \\\n",
       "0      0.923416  0.766704  0.507328  0.032670 -0.253998 -0.419199   \n",
       "1      0.756851  1.094751  0.322661 -0.243856 -0.151363 -0.110732   \n",
       "2      0.873377  1.033490  0.357246 -0.110494 -0.465703 -0.216796   \n",
       "3      0.627257  0.524419  0.019521  0.155198 -0.285741  0.180573   \n",
       "4      1.029964  1.230545  0.656802  0.384140 -0.032551 -0.146348   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "10046  1.191250  0.453020  0.596119  0.018052 -0.095915 -0.052083   \n",
       "10047  1.350083  0.619704  0.198073 -0.642915  0.407108  0.066086   \n",
       "10048  1.339037  0.293813  0.480016 -0.927876  0.001489 -0.515470   \n",
       "10049  1.274414  0.386450  0.689333 -0.483685 -0.168044 -0.327015   \n",
       "10050  0.967440  0.748833  0.857725 -0.198816  0.128243 -0.521847   \n",
       "\n",
       "             Category  \n",
       "0               beers  \n",
       "1               beers  \n",
       "2               beers  \n",
       "3               beers  \n",
       "4               beers  \n",
       "...               ...  \n",
       "10046  hotel bookings  \n",
       "10047  hotel bookings  \n",
       "10048  hotel bookings  \n",
       "10049  hotel bookings  \n",
       "10050  hotel bookings  \n",
       "\n",
       "[10051 rows x 1025 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if UPDATE_VENDOR_DATABASE:\n",
    "    create_embedded_vendor_database()\n",
    "\n",
    "if UPDATE_PRODUCT_DATABASE:\n",
    "    create_embedded_product_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d745e",
   "metadata": {},
   "source": [
    "# 3) Vendor and Product Category Receipt Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90e4f4",
   "metadata": {},
   "source": [
    "## Split Vector Database into X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bdcc3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_database(file_path):\n",
    "    '''\n",
    "    Splits vector database csv into X and y.\n",
    " \n",
    "    Parameters:\n",
    "    file_path (str): The path to the vector database.\n",
    "\n",
    "    Returns:\n",
    "    tuple(dataframe, dataframe): X and y.\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "    # Creating variables from database values\n",
    "    X = df.drop('Category', axis=1)\n",
    "    y = df['Category']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206438b",
   "metadata": {},
   "source": [
    "## Perform K-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0bf30229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Performs K-Nearest Neighbors Classificatiton.\n",
    " \n",
    "    Parameters:\n",
    "    X_train (dataframe): The X training dataframe.\n",
    "    y_train (dataframe): The y training dataframe.\n",
    "    X_test (dataframe): The X test dataframe.\n",
    "    \n",
    "    Returns:\n",
    "    dataframe: The predicted categories (y_pred).\n",
    "    '''\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=20)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f00613",
   "metadata": {},
   "source": [
    "## Run Vendor Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1305d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ggaav\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_vendor_category(): \n",
    "    '''\n",
    "    Runs classification of vendor category on all receipts.\n",
    "    Outputs prediction results to ./predictions/vendor_category_predictions.csv.\n",
    "    '''\n",
    "    \n",
    "    X_train, y_train = split_database('./databases/vendor/embedding/embedded_vendor_database.csv')\n",
    "    \n",
    "    receipts = pd.read_csv(\"./processed_receipts/vendors_and_products.csv\")\n",
    "    vendors = receipts['Vendors'].to_frame()\n",
    "    \n",
    "    vendors_embeddings = convert_to_embeddings_df(vendors)\n",
    "    X_test = vendors_embeddings.values\n",
    "    \n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    result_df = pd.concat([vendors, results], axis=1)\n",
    "    return result_df\n",
    "\n",
    "# Dump predictions to csv\n",
    "get_vendor_category().to_csv('./predictions/vendor_category_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12634bd",
   "metadata": {},
   "source": [
    "## Run Product Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df0af313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ggaav\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def process_list(row):\n",
    "    '''\n",
    "    Helper function to add vendor to product description to improve classifcation performance.\n",
    " \n",
    "    Parameters:\n",
    "    row (dataframe): The row of a dataframe.\n",
    "    \n",
    "    Returns:\n",
    "    tuple(list[str], list[str]): The X_test of vendor and product description combined \n",
    "                                 and the product decscription themselves.\n",
    "    '''\n",
    "    \n",
    "    X_test, items = [], []\n",
    "    for item in row['Products']:\n",
    "        X_test.append(item + \" \" + row['Vendors'])\n",
    "        items.append(item)\n",
    "    return X_test, items\n",
    "        \n",
    "def get_product_category():\n",
    "    '''\n",
    "    Runs classification of product category on all receipts.\n",
    "    Outputs prediction results to ./predictions/product_category_predictions.csv.\n",
    "    '''\n",
    "    \n",
    "    X_train, y_train = split_database('./databases/product/embedding/embedded_product_database.csv')\n",
    "    \n",
    "    receipts = pd.read_csv('./processed_receipts/vendors_and_products.csv')  \n",
    "    receipts['Products'] = receipts['Products'].apply(eval)\n",
    "    receipts = receipts.apply(process_list, axis=1)\n",
    "    \n",
    "    X_test = [item[0] for item in receipts]\n",
    "    items = [item[1] for item in receipts]\n",
    "    \n",
    "    receipt_items, merchant_items = [], []\n",
    "    for i, product in enumerate(items):\n",
    "        product = items[i]\n",
    "        for item in product:\n",
    "            receipt_items.append(item)\n",
    "        for merchant_item in X_test[i]:\n",
    "            merchant_items.append(merchant_item)\n",
    "    \n",
    "    X_test = pd.DataFrame(merchant_items)\n",
    "    receipt_embeddings = convert_to_embeddings_df(X_test)\n",
    "    X_test = receipt_embeddings.values\n",
    "\n",
    "    results = pd.DataFrame(KNN(X_train, y_train, X_test), columns=['KNN Prediction']) \n",
    "    receipt_items = pd.DataFrame(receipt_items)\n",
    "    result_df = pd.concat([receipt_items, results], axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Dump predictions to csv\n",
    "get_product_category().to_csv('./predictions/product_category_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1273d48",
   "metadata": {},
   "source": [
    "# 4) Create tests in python\n",
    "\n",
    "* Functions that just test one test and shows that tests passed/failed\n",
    "* At the end shows how many passed and how many failed\n",
    "\n",
    "- Example:\n",
    "\n",
    "     - handleVendor.py\n",
    "     - all test functions tested in testHandleCategory.py (test all the functions in hangleVendor.py) asserts at the end of each test function\n",
    "\n",
    "     - Fixtures in test file: testing all of the things that are needed for the code to run\n",
    "\n",
    "- For part 2, test for:\n",
    "    - If 7 categories, one of the 7 categories and one of the 7 categories\n",
    "    - Edge cases (ex: error in formatting, must be string in list of possible categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209423a1",
   "metadata": {},
   "source": [
    "# 5) Visualization using Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4cc416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run visualization.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
